import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import matplotlib.pyplot as plt
import shap
import xgboost as xgb
import os
import joblib
from sklearn.preprocessing import LabelEncoder, label_binarize
from sklearn.metrics import roc_curve, auc

# --------------------------------------------------------------------------------
# 0. CLASS DEFINITION & UTILS
# --------------------------------------------------------------------------------
class RollingEnsembleClassifier:
    def __init__(self):
        self.estimators = []
        self.classes_ = None

    def add_model(self, scaler, model, period_name):
        self.estimators.append({
            'scaler': scaler,
            'model': model,
            'period': period_name
        })
        if self.classes_ is None:
            self.classes_ = model.classes_

    def predict_proba(self, X):
        if not self.estimators:
            raise ValueError("No models added.")
        
        avg_proba = None
        for item in self.estimators:
            scaler = item['scaler']
            model = item['model']
            
            # Feature Alignment
            if isinstance(X, pd.DataFrame) and hasattr(scaler, 'feature_names_in_'):
                 X_input = X.reindex(columns=scaler.feature_names_in_, fill_value=0)
            else:
                 X_input = X
            
            X_scaled = scaler.transform(X_input)
            proba = model.predict_proba(X_scaled)
            
            if avg_proba is None:
                avg_proba = proba
            else:
                avg_proba += proba
                
        avg_proba /= len(self.estimators)
        return avg_proba

    def predict(self, X):
        proba = self.predict_proba(X)
        return self.classes_[np.argmax(proba, axis=1)]



# ---------------------------------------------------------------------------------
# [ì „ëµ ì œì•ˆ ë”•ì…”ë„ˆë¦¬ - 19ê°œ ì§€í‘œ ëŒ€ì‘]
STRATEGIC_ADVICE = {
    "TQ": {"pos": "ì‹œì¥ ê°€ì¹˜(Tobin's Q)ê°€ ë†’ì•„ ë¯¸ë˜ ì„±ì¥ì„±ì— ëŒ€í•œ ì‹ ë¢°ê°€ ë‘í…ìŠµë‹ˆë‹¤.", "neg": "ìì‚° ëŒ€ë¹„ ì‹œì¥ ê°€ì¹˜ê°€ ì €í‰ê°€ë˜ì–´ ìˆìŠµë‹ˆë‹¤. IR ê°•í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤."},
    "ROA": {"pos": "ìš°ìˆ˜í•œ ìì‚° íš¨ìœ¨ì„±(ROA)ì´ ESG ê²½ì˜ì˜ í† ëŒ€ê°€ ë©ë‹ˆë‹¤.", "neg": "ìˆ˜ìµì„± ì €í•˜ê°€ ESG íˆ¬ì ì—¬ë ¥ì„ ì œí•œí•˜ê³  ìˆìŠµë‹ˆë‹¤."},
    "SGR": {"pos": "ê²¬ê³ í•œ ë§¤ì¶œ ì„±ì¥ì„¸ê°€ ê¸°ì—… í™œë ¥ì„ ì¦ëª…í•©ë‹ˆë‹¤.", "neg": "ì„±ì¥ ì •ì²´ ë¦¬ìŠ¤í¬ê°€ ì¡´ì¬í•©ë‹ˆë‹¤. ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ ì „í™˜ì„ ê²€í† í•˜ì„¸ìš”."},
    "LEV": {"pos": "ì•ˆì •ì ì¸ ë¶€ì±„ë¹„ìœ¨ì´ ì¬ë¬´ ë¦¬ìŠ¤í¬ë¥¼ ë°©ì–´í•©ë‹ˆë‹¤.", "neg": "ë†’ì€ ë¶€ì±„ë¹„ìœ¨ì´ ì¬ë¬´ ë¶ˆì•ˆì •ì„±ì„ í‚¤ìš°ê³  ìˆìŠµë‹ˆë‹¤."},
    "A_SIZE": {"pos": "ê·œëª¨ì˜ ê²½ì œë¥¼ ê°–ì¶˜ ëŒ€ê¸°ì—…ìœ¼ë¡œì„œ ESG ì—­ëŸ‰ì´ ìš°ìˆ˜í•©ë‹ˆë‹¤.", "neg": "ì‘ì€ ìì‚° ê·œëª¨ë¡œ ì¸í•œ ESG ê´€ë¦¬ í•œê³„ë¥¼ íš¨ìœ¨í™”ë¡œ ê·¹ë³µí•´ì•¼ í•©ë‹ˆë‹¤."},
    "W_YEAR": {"pos": "ë†’ì€ ê·¼ì†ì—°ìˆ˜ëŠ” ì¸ì  ìì›ì˜ ì•ˆì •ì„±ì„ ëœ»í•©ë‹ˆë‹¤.", "neg": "ì§§ì€ ê·¼ì†ì—°ìˆ˜ëŠ” ì¸ë ¥ ìœ ì¶œ ë¦¬ìŠ¤í¬ë¥¼ ì‹œì‚¬í•©ë‹ˆë‹¤."},
    "Fe_R": {"pos": "ì—¬ì„± ì§ì› ë¹„ìœ¨ì´ ë†’ì•„ ë‹¤ì–‘ì„± ì¸¡ë©´ì—ì„œ ê¸ì •ì ì…ë‹ˆë‹¤.", "neg": "ì¸ë ¥ êµ¬ì¡°ì˜ ë‹¤ì–‘ì„±ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. ì±„ìš© ì •ì±…ì„ ì ê²€í•˜ì„¸ìš”."},
    "Re_R": {"pos": "ë†’ì€ ì •ê·œì§ ë¹„ìœ¨ì€ ê³ ìš©ì˜ ì§ˆì´ ìš°ìˆ˜í•¨ì„ ëœ»í•©ë‹ˆë‹¤.", "neg": "ë¹„ì •ê·œì§ ë¹„ì¤‘ì´ ë†’ì•„ ê³ ìš© ì•ˆì •ì„± ë¦¬ìŠ¤í¬ê°€ ìˆìŠµë‹ˆë‹¤."},
    "SA": {"pos": "ìš°ìˆ˜í•œ ì„ê¸ˆ ìˆ˜ì¤€ì´ ì¸ì¬ í™•ë³´ ê²½ìŸë ¥ì„ ë†’ì…ë‹ˆë‹¤.", "neg": "ë‚®ì€ ì„ê¸ˆ ìˆ˜ì¤€ì€ ì¸ì¬ ì´íƒˆ ì›ì¸ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤."},
    "Pay_Gap": {"pos": "ë‚®ì€ ì„ê¸ˆ ê²©ì°¨ëŠ” ì¡°ì§ ë‚´ í˜•í‰ì„±ì´ ë†’ìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.", "neg": "ì‚¬ë‚´ ì„ê¸ˆ ê²©ì°¨ê°€ ì»¤ ì¡°ì§ ê²°ì†ë ¥ì„ í•´ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤."},
    "FOR": {"pos": "ë†’ì€ ì™¸êµ­ì¸ ì§€ë¶„ìœ¨ì´ ê²½ì˜ íˆ¬ëª…ì„±ì„ ë³´ì¥í•©ë‹ˆë‹¤.", "neg": "ì™¸êµ­ì¸ íˆ¬ììì˜ ê´€ì‹¬ë„ê°€ ë‚®ìŠµë‹ˆë‹¤. ì˜ë¬¸ ê³µì‹œë¥¼ í™•ëŒ€í•˜ì„¸ìš”."},
    "MSE": {"pos": "ì ì ˆí•œ ëŒ€ì£¼ì£¼ ì§€ë¶„ìœ¨ì´ ê²½ì˜ ì•ˆì •ì„±ì„ ì œê³µí•©ë‹ˆë‹¤.", "neg": "ì§€ë¶„ êµ¬ì¡°ê°€ ì§€ë‚˜ì¹˜ê²Œ ì§‘ì¤‘ë˜ì–´ ì´ì‚¬íšŒì˜ ë…ë¦½ì„±ì´ ìš°ë ¤ë©ë‹ˆë‹¤."},
    "DIR_OUT": {"pos": "ë†’ì€ ì‚¬ì™¸ì´ì‚¬ ë¹„ìœ¨ì´ ê²¬ì œì™€ ê· í˜•ì„ ë•ê³  ìˆìŠµë‹ˆë‹¤.", "neg": "ì‚¬ì™¸ì´ì‚¬ ë¹„ì¤‘ì´ ë‚®ì•„ ì´ì‚¬íšŒì˜ ë…ë¦½ì„±ì´ ìš°ë ¤ë©ë‹ˆë‹¤."},
    "DIR_FE": {"pos": "ê²½ì˜ì§„ ë‚´ ì—¬ì„± ë¹„ìœ¨ì´ ë†’ì•„ ì˜ì‚¬ê²°ì • ë‹¤ì–‘ì„±ì´ í™•ë³´ë˜ì—ˆìŠµë‹ˆë‹¤.", "neg": "ì˜ì‚¬ê²°ì • ê¸°êµ¬ì˜ ì„±ë³„ ë‹¤ì–‘ì„±ì´ ë¶€ì¡±í•©ë‹ˆë‹¤."},
    "SGAE_R": {"pos": "íš¨ìœ¨ì ì¸ íŒê´€ë¹„ ê´€ë¦¬ê°€ ìˆ˜ìµì„± ê°œì„ ìœ¼ë¡œ ì´ì–´ì§‘ë‹ˆë‹¤.", "neg": "ë§¤ì¶œ ëŒ€ë¹„ íŒê´€ë¹„ ë¹„ì¤‘ì´ ë†’ì•„ ìš´ì˜ íš¨ìœ¨í™”ê°€ ì‹œê¸‰í•©ë‹ˆë‹¤."},
    "DIV": {"pos": "ì£¼ì£¼ í™˜ì› ì •ì±…ì´ ìš°ìˆ˜í•˜ì—¬ Gë“±ê¸‰ì— ê¸ì •ì ì…ë‹ˆë‹¤.", "neg": "ì ê·¹ì ì¸ ë°°ë‹¹ ì •ì±…ìœ¼ë¡œ ì£¼ì£¼ ì‹ ë¢°ë¥¼ íšŒë³µí•˜ì„¸ìš”."},
    "DIV_enco": {"pos": "ë°°ë‹¹ ì‹¤ì ì´ ì£¼ì£¼ ì¹œí™” ê²½ì˜ì„ ì¦ëª…í•©ë‹ˆë‹¤.", "neg": "ë°°ë‹¹ ë„ì…ì„ í†µí•´ ì§€ë°°êµ¬ì¡° ì ìˆ˜ë¥¼ ë³´ì™„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."},
    "DIR_FE_enco": {"pos": "ì—¬ì„± ì„ì› ì„ ì„ì€ ê±°ë²„ë„ŒìŠ¤ ì„ ì§„í™”ì˜ ì‹ í˜¸ì…ë‹ˆë‹¤.", "neg": "ì—¬ì„± ì„ì› ì„ ì„ì„ í†µí•´ ì´ì‚¬íšŒ ë‹¤ì–‘ì„±ì„ í™•ë³´í•˜ì„¸ìš”."},
    "ESG_lag": {
        "pos": "ê³¼ê±°ì˜ ìš°ìˆ˜í•œ ESG ê²½ì˜ ì„±ê³¼ê°€ í˜„ì¬ ë“±ê¸‰ì„ ê²¬ê³ í•˜ê²Œ ì§€ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
        "neg": "ê³¼ê±°ì˜ ë‚®ì€ ë“±ê¸‰ì´ í˜„ì¬ í‰ê°€ì— í•˜ë°© ì••ë ¥ì„ ì£¼ê³  ìˆìŠµë‹ˆë‹¤. êµ¬ì¡°ì  í˜ì‹ ì´ í•„ìš”í•©ë‹ˆë‹¤."
    },
    "A_SIZE_FOR_inter": {
        "pos": "ê¸°ì—… ê·œëª¨ì™€ ì™¸êµ­ì¸ íˆ¬ììì˜ ê°ì‹œ ì²´ê³„ê°€ ì‹œë„ˆì§€ë¥¼ ë‚´ì–´ ì§€ë°°êµ¬ì¡° ì ìˆ˜ë¥¼ ë†’ì´ê³  ìˆìŠµë‹ˆë‹¤.",
        "neg": "ìì‚° ê·œëª¨ ëŒ€ë¹„ ì™¸êµ­ì¸ íˆ¬ììì˜ ê¸ì •ì  ì˜í–¥ë ¥ì´ ì¶©ë¶„íˆ ë°œíœ˜ë˜ì§€ ëª»í•˜ê³  ìˆìŠµë‹ˆë‹¤."
    }

}


# [ì œì•ˆ ìƒì„± í•¨ìˆ˜]
def make_shap_based_advice(tmp_df, model_in, advice_dict, top_k=3):
    results = {"pos": [], "neg": []}
    for _, row in tmp_df.iterrows():
        feat = str(row["feature"]).strip()
        if feat in advice_dict:
            val = model_in.iloc[0][feat] if feat in model_in.columns else None
            # SHAP ê°’ì´ ì–‘ìˆ˜ë©´ pos, ìŒìˆ˜ë©´ neg
            if row["shap"] > 0:
                if len(results["pos"]) < top_k:
                    results["pos"].append({"feature": feat, "value": val, "text": advice_dict[feat]["pos"]})
            else:
                if len(results["neg"]) < top_k:
                    results["neg"].append({"feature": feat, "value": val, "text": advice_dict[feat]["neg"]})
    return results
# --------------------------------------------------------------------------------








# --------------------------------------------------------------------------------
# 1. PAGE CONFIGURATION
# --------------------------------------------------------------------------------
st.set_page_config(
    page_title="ESG Prediction Dashboard",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown("""
    <style>
    .stApp { background-color: #FFFFFF; color: #000000; }
    h1, h2, h3, h4, h5, h6 { color: #4B0082 !important; font-family: 'Helvetica Neue', sans-serif; }
    .home-title { text-align: center; color: #4B0082; font-size: 3.5rem; font-weight: 800; margin-top: 50px; }
    .home-subtitle { text-align: center; color: #DAA520; font-size: 1.8rem; font-weight: 500; margin-bottom: 20px; }
    .team-names { text-align: center; color: #333333; font-size: 1.2rem; margin-top: 10px; margin-bottom: 50px; }
    .info-box { padding: 20px; background-color: #f8f9fa; border-left: 5px solid #4B0082; border-radius: 5px; margin-bottom: 20px; }
    .warning-box { padding: 20px; background-color: #fff3cd; border-left: 5px solid #ffc107; border-radius: 5px; margin-bottom: 20px; }
    .stButton>button { background-color: #4B0082; color: #DAA520; font-weight: bold; width: 100%; }
    .metric-container { background-color: #F0F2F6; padding: 10px; border-radius: 10px; text-align: center; }
    </style>
""", unsafe_allow_html=True)

COLOR_MAIN = '#4B0082'
COLOR_ACCENT = '#DAA520'
COLOR_ALERT = '#FF4B4B'

# --------------------------------------------------------------------------------
# 2. DATA LOADING & PREPROCESSING
# --------------------------------------------------------------------------------
@st.cache_data
def load_data_basic():
    # ê²½ë¡œ: data/fin/fin_total_all_years.csv
    file_path = os.path.join("data", "fin", "fin_total_all_years.csv")
    if not os.path.exists(file_path): return None
    df = pd.read_csv(file_path)
    if 'Unnamed: 0' in df.columns: df = df.drop(columns=['Unnamed: 0'])
    return df.dropna().copy()

@st.cache_data
def load_data_advanced():
    # ê²½ë¡œ: data/X_features_fin.csv
    file_path = os.path.join("data", "X_features_fin.csv")
    if not os.path.exists(file_path): return None, None, None, None

    df = pd.read_csv(file_path)
    if 'Unnamed: 0' in df.columns: df = df.drop(columns=['Unnamed: 0'])
    df = df.sort_values(by=['corp_code', 'year'])

    # ì „ì²˜ë¦¬: ì‚°ì—…êµ°ë³„ ì¤‘ì•™ê°’ ëŒ€ì²´
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    exclude = ['corp_code', 'stock_code', 'year', 'IND']
    targets = [c for c in numeric_cols if c not in exclude]

    if 'IND' in df.columns:
        df[targets] = df.groupby('IND')[targets].transform(lambda x: x.fillna(x.median()))
    df[targets] = df[targets].fillna(df[targets].median())

    # [ìˆ˜ì •] Target ìƒì„±: Shift ì œê±°
    # ì›ë³¸ ë°ì´í„°ì˜ ESG ì»¬ëŸ¼ì´ ì´ë¯¸ T+1 ì‹œì ì˜ ì •ë‹µ ë°ì´í„°ë¼ê³  í™•ì¸ë¨.
    df['Target_Grade'] = df['ESG'] 
    
    # Targetì´ ìˆëŠ” ë°ì´í„°ë§Œ ì‚¬ìš©
    df_fin = df.dropna(subset=['Target_Grade']).copy()
    
    # ê²€ìƒ‰ìš© ë°ì´í„° (ì˜ˆì¸¡ ëŒ€ìƒ ì—°ë„ = ì¬ë¬´ë…„ë„ + 1)
    full_search = df.copy()
    full_search['year'] = full_search['year'] + 1 

    # X, y ìƒì„±
    drop_cols = ['corp_name', 'G', 'S', 'E', 'stock_code', 'corp_code', 'year', 'ESG', 'Target_Grade']
    X = df_fin.drop(columns=[c for c in drop_cols if c in df_fin.columns])
    if 'IND' in X.columns: X = pd.get_dummies(X, columns=['IND'], prefix='IND')
    y_cls = df_fin['Target_Grade']
    
    return X, y_cls, df_fin, full_search

# --------------------------------------------------------------------------------
# 3. MODEL LOADING
# --------------------------------------------------------------------------------
@st.cache_resource
def load_models():
    models = {}
    try:
        # íŒŒì¼ ê²½ë¡œ í™•ì¸
        base_dir = os.path.dirname(os.path.abspath(__file__))
        
        # ëª¨ë¸ ë¡œë“œ
        models['reg_fin'] = joblib.load(os.path.join(base_dir, 'esg_model_regression_fin.pkl'))
        models['scaler_reg_fin'] = joblib.load(os.path.join(base_dir, 'esg_scaler_regression_fin.pkl'))
        models['cls_select'] = joblib.load(os.path.join(base_dir, 'esg_model_classifier_select.pkl'))
        models['final'] = joblib.load(os.path.join(base_dir, 'esg_model_classifier_final_depth7.pkl'))
        
        # í™•ì¥í˜• ëª¨ë¸ ë¡œë“œ
        models['ext_model'] = joblib.load(os.path.join(base_dir, 'xgb_model_ext.pkl'))
        models['ext_scaler'] = joblib.load(os.path.join(base_dir, 'scaler_ext.pkl'))

    except Exception as e:
        # ì—ëŸ¬ ë°œìƒ ì‹œ í™”ë©´ì— ë¶‰ì€ ë°•ìŠ¤ë¡œ í‘œì‹œ (ë§¤ìš° ì¤‘ìš”!)
        st.error(f"ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
        st.info("requirements.txtì˜ scikit-learn ë²„ì „ì„ í™•ì¸í•˜ê±°ë‚˜, pkl íŒŒì¼ì´ ê¹ƒí—ˆë¸Œì— ì˜ ì˜¬ë¼ê°”ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        
    return models

df_basic = load_data_basic()
X_adv, y_cls_adv, df_adv, full_search_df = load_data_advanced()
models = load_models()

# Label Encoder (D to S)
if y_cls_adv is not None:
    unique_classes = sorted(y_cls_adv.unique())
    le = LabelEncoder()
    le.fit(unique_classes)

# --------------------------------------------------------------------------------
# MAIN TABS
# --------------------------------------------------------------------------------
tab_home, tab_overview, tab_reg, tab_cls, tab_final, tab_pred = st.tabs([
    "HOME", "OVERVIEW", "REGRESSION", "CLASSIFICATION", "FINAL MODEL", "PREDICTOR"
])

# ==============================================================================
# TAB 1: HOME
# ==============================================================================
with tab_home:
    st.markdown('<div class="home-title">ESG Prediction Project</div>', unsafe_allow_html=True)
    st.markdown('<div class="home-subtitle">Financial Data Based Forecasting</div>', unsafe_allow_html=True)
    st.markdown("""
        <div class="team-names">
            <b>Team Members</b><br>
            Park Hyun-woo | Min Sun-ah
        </div>
        """, unsafe_allow_html=True)
    st.markdown("---")
    col1, col2, col3 = st.columns([1,2,1])
    with col2:
        st.info("ğŸ’¡ **Project Goal:** ì¬ë¬´ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ ê¸°ì—…ì˜ ì°¨ë…„ë„(T+1) ESG ë“±ê¸‰ì„ ì˜ˆì¸¡í•˜ê³ , ê°œì„  ê°€ì´ë“œë¥¼ ì œê³µí•˜ëŠ” ëª¨ë¸ë§")

# ==============================================================================
# TAB 2: OVERVIEW
# ==============================================================================
with tab_overview:
    st.subheader("Features & Performance Overview")
    st.markdown("""
        <div class="info-box">
        <b>ì„±ê³¼ ìš”ì•½:</b><br>
        ê¸°ì¡´ ì„ í–‰ ì—°êµ¬(RÂ² 0.225) ëŒ€ë¹„ ìš°ë¦¬ ëª¨ë¸ì€ <b>RÂ² 0.585</b>ë¡œ ì„¤ëª…ë ¥ì„ ëŒ€í­ ê°œì„ í•˜ì˜€ìœ¼ë©°,<br>
        ë¶„ë¥˜ ëª¨ë¸(XGBoost) ì „í™˜ í›„ <b>AUC 0.829</b>ì˜ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ì˜€ìŠµë‹ˆë‹¤.<br>
        * ë…¼ë¬¸ ì°¸ì¡°: ì´ì¬ì˜, ì°¨ìš°ì°½(2024) â€œë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ í™œìš©í•œ ESG í™œë™ê³¼ ê¸°ì—… ê°€ì¹˜ ë¶„ì„â€, í•œêµ­ì‚°ì—…ê²½ì˜ì‹œìŠ¤í…œí•™íšŒì§€ 47(4), 76-86.
        </div>
        """, unsafe_allow_html=True)
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("### ğŸ”¹ Initial X_features")
        st.markdown("""
        | ë³€ìˆ˜ëª… | ì„¤ëª… | ë¹„ê³  |
        |---|---|---|
        | **A_SIZE** | log(ì´ìì‚°) | ê¸°ì—… ê·œëª¨ |
        | **LEV** | ì´ë¶€ì±„ / ì´ìì‚° | ë¶€ì±„ ë¹„ìœ¨ |
        | **TQ** | (ì‹œê°€ì´ì•¡+ì´ë¶€ì±„)/ì´ìì‚° | **Tobins'Q** |
        | **FOR** | ì™¸êµ­ì¸ ì§€ë¶„ìœ¨ | ê¸€ë¡œë²Œ ëª¨ë‹ˆí„°ë§ |
        | **MSE** | ì£¼ìš”ì£¼ì£¼ ì§€ë¶„ìœ¨ | ì†Œìœ  êµ¬ì¡° |
        | **ROA** | ì´ìì‚° ìˆ˜ìµë¥  | ìˆ˜ìµì„± |
        | **ADV** | ê´‘ê³ ì„ ì „ë¹„ | ê°€ì‹œì„± |
        | **SGR** | ë§¤ì¶œì•¡ ì„±ì¥ë¥  | ì„±ì¥ì„± |
        | **R&D** | ì—°êµ¬ê°œë°œë¹„ | í˜ì‹ ì„± |
        """)
        
    with col2:
        st.markdown("### ğŸ”¸ Advanced X_features")
        st.markdown("""
        | ë³€ìˆ˜ëª… | ì„¤ëª… | ë¹„ê³  |
        |---|---|---|
        | **SGAE_R** | íŒê´€ë¹„ ë¹„ìœ¨ | **ADV + R&D ê²°í•©** |
        | **Fe_R** | ë‚¨ì„± ëŒ€ë¹„ ì—¬ì„± ì§ì› ë¹„ìœ¨ | ë‹¤ì–‘ì„± |
        | **Re_R** | ì •ê·œì§ ë¹„ìœ¨ | ê³ ìš© ì•ˆì •ì„± |
        | **SA** | log(1ì¸ë‹¹ í‰ê· ì„ê¸ˆ) | ì§ì› ì²˜ìš° |
        | **Pay_Gap** | ë‚¨ë…€ ì„ê¸ˆ ê²©ì°¨ | ê³µì •ì„± |
        | **W_YEAR** | í‰ê·  ê·¼ì†ì—°ìˆ˜ | ì¡°ì§ ì•ˆì •ì„± |
        | **DIV** | ì£¼ê°€ ë°°ë‹¹ìœ¨ | ì£¼ì£¼ í™˜ì› |
        | **DIR_FE** | ì—¬ì„± ì„ì› ë¹„ìœ¨ | ì´ì‚¬íšŒ ë‹¤ì–‘ì„± |
        | **DIR_OUT** | ì‚¬ì™¸ì´ì‚¬ ë¹„ìœ¨ | ì´ì‚¬íšŒ ë…ë¦½ì„± |
        """)

    with col3:
        st.markdown("### ğŸ† Performance Milestone")
        st.write("") 
        milestone_df = pd.DataFrame({
            "Stage": ["Previous Research", "Initial Regression", 'Plus Regression', "Advanced Regression", 'Base Classification', "Final Classification"],
            "Metric": ["RÂ² Score", "RÂ² Score", 'RÂ² Score', "RÂ² Score", "ROC-AUC", "ROC-AUC"],
            "Score": [0.225, 0.440, 0.585, 0.664, 0.800, 0.829]
        })
        st.table(milestone_df.style.format({"Score": "{:.3f}"}).set_properties(**{'text-align': 'center', 'font-size': '16px'}))
        
    st.markdown("---")    
    st.markdown(f"""
    <div style="background-color: {COLOR_MAIN}; padding: 15px; border-radius: 5px; color: white; text-align: center; margin-top: 20px;">
    <b>"ì´ì „ ì—°êµ¬ì—ì„œ ë³´ì˜€ë˜ ë‚®ì€ ì„¤ëª…ë ¥ì„<br>ìµœì¢… ROC_AUC 0.829ë¡œ í¬ê²Œ ë°œì „"</b>
    </div>
    """, unsafe_allow_html=True)

# ==============================================================================
# TAB 3: REGRESSION ANALYSIS
# ==============================================================================
with tab_reg:
    st.subheader("Regression Analysis Process")
    
    st.markdown("""
    <div class="info-box">
    <b>íšŒê·€ë¶„ì„ ê³¼ì • ìš”ì•½:</b><br>
    ì´ˆê¸° ëª¨ë¸(Initial)ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ íŒŒìƒë³€ìˆ˜ ì¶”ê°€(Advanced) ë° ë¡¤ë§ ìœˆë„ìš° ìµœì í™”ë¥¼ ìˆ˜í–‰í•˜ì˜€ìŠµë‹ˆë‹¤.<br>
    ë¶„ì„ ê²°ê³¼, <b>ìµœì ì˜ Window SizeëŠ” 3ë…„(RÂ² 0.585)</b>ìœ¼ë¡œ ë„ì¶œë˜ì—ˆìœ¼ë‚˜, ì—¬ì „íˆ ì¡´ì¬í•˜ëŠ” ì„±ëŠ¥ í•œê³„(í•™ìŠµ ê³¡ì„  ì •ì²´)ë¥¼ í™•ì¸í•˜ê³  ë¶„ë¥˜ ëª¨ë¸ë¡œì˜ ì „í™˜ì„ ê²°ì •í•˜ì˜€ìŠµë‹ˆë‹¤.
    </div>
    """, unsafe_allow_html=True)
    
    sub_tab1, sub_tab2, sub_tab3 = st.tabs(["1. Initial Model", "2. Feature Expanded", "3. Final Regression"])
    
    with sub_tab1:
        st.markdown("#### Initial Model Performance (Total vs Sector)")
        c1, c2 = st.columns([1.5, 1])
        with c1:
            st.markdown("**Correlation Matrix (Include ESG)**")
            if df_basic is not None:
                df_corr = df_basic.copy()
                grade_map = {'S': 7.0, 'A+': 6.0, 'A': 5.0, 'B+': 4.0, 'B': 3.0, 'C': 2.0, 'D': 1.0}
                if 'ESG' in df_corr.columns:
                    df_corr['ESG'] = df_corr['ESG'].map(grade_map)
                
                exclude_cols = ['corp_name', 'stock_code', 'corp_code', 'year']
                df_corr = df_corr.drop(columns=[c for c in exclude_cols if c in df_corr.columns])
                
                corr = df_corr.select_dtypes(include=[np.number]).corr()
                fig_heat = px.imshow(corr, text_auto=".2f", aspect="auto", color_continuous_scale='RdBu_r')
                fig_heat.update_layout(height=700, font=dict(size=14))
                st.plotly_chart(fig_heat, use_container_width=True)
        with c2:
            st.markdown("**RÂ² Score by Sector**")
            sectors = ['Total Model', 'E (Environment)', 'S (Social)', 'G (Governance)']
            scores = [0.440, 0.422, 0.450, 0.244]
            colors = [COLOR_MAIN, COLOR_MAIN, COLOR_MAIN, COLOR_ALERT]
            
            fig_bar = go.Figure(go.Bar(
                x=scores, y=sectors, orientation='h',
                text=scores, marker_color=colors, textposition='auto'
            ))
            fig_bar.update_layout(xaxis_range=[0, 0.6], height=500, font=dict(size=15))
            st.plotly_chart(fig_bar, use_container_width=True)
            
            st.markdown(f"""
            <div class="warning-box">
            <b>ğŸ“‰ ë¶„ì„ ê²°ê³¼:</b><br>
            G(ì§€ë°°êµ¬ì¡°) ë¶„ì•¼ëŠ” ì •ì„±ì  ìš”ì†Œê°€ ê°•í•´ ì™¸í˜•ì  ì¬ë¬´ ì§€í‘œë§Œìœ¼ë¡œëŠ” ì„¤ëª…í•˜ê¸° ì–´ë µë‹¤ëŠ” í•œê³„ í™•ì¸
            </div>
            """, unsafe_allow_html=True)

    with sub_tab2:
        st.markdown("#### Feature Expansion & Optimization")
        
        col_lc, col_rw = st.columns(2)
        with col_lc:
            st.markdown("**Learning Curve (RÂ²)**")
            train_sizes = np.linspace(0.1, 1.0, 7)
            train_scores = [0.59, 0.588, 0.585, 0.585, 0.585, 0.585, 0.585]
            val_scores =   [-1.5, -0.8, -0.2, 0.2, 0.4, 0.5, 0.57]
            
            fig_lc = go.Figure()
            fig_lc.add_trace(go.Scatter(x=train_sizes, y=train_scores, mode='lines+markers', name='Training Score', line=dict(color='red')))
            fig_lc.add_trace(go.Scatter(x=train_sizes, y=val_scores, mode='lines+markers', name='Validation Score', line=dict(color='green')))
            fig_lc.update_layout(yaxis_range=[-1.5, 1], xaxis_title="Training Samples", yaxis_title="RÂ² Score")
            st.plotly_chart(fig_lc, use_container_width=True)
            
            st.info("ğŸ“¢ **íšŒê·€ Base Modelì˜ í•™ìŠµ í•œê³„ í™•ì¸ (ë°ì´í„°ê°€ ëŠ˜ì–´ë„ ì„±ëŠ¥ ì •ì²´)**")
            
        with col_rw:
            st.markdown("**Rolling Window Performance**")
            windows = [2, 3, 4, 5]
            rw_scores = [0.386, 0.585, 0.572, 0.568]
            
            fig_rw = go.Figure()
            fig_rw.add_trace(go.Scatter(x=windows, y=rw_scores, mode='lines+markers', line=dict(width=3, color=COLOR_MAIN)))
            fig_rw.add_trace(go.Scatter(x=[3], y=[0.585], mode='markers', marker=dict(size=15, color='red'), name='Best'))
            fig_rw.add_annotation(x=3, y=0.585, text="Best: 0.585", showarrow=True, arrowhead=1)
            fig_rw.update_layout(xaxis_title="Window Size (Year)", yaxis_title="RÂ²")
            st.plotly_chart(fig_rw, use_container_width=True)
            
            st.info("ğŸ“¢ **ìµœì  Window Size 3ë…„ (RÂ² 0.585) ë„ì¶œ **")

        st.markdown("---")
        st.markdown("**Model Performance Comparison (Optimization)**")
        sorted_models = ['DecisionTree', 'Linear', 'RandomForest', 'LightGBM', 'XGBoost']
        test_r2 = [0.302, 0.585, 0.606, 0.637, 0.664]
        train_r2 = [0.304, 0.580, 0.676, 0.755, 0.795]
        
        fig_ms = go.Figure()
        fig_ms.add_trace(go.Scatter(x=sorted_models, y=train_r2, mode='lines+markers', name='Train RÂ²', line=dict(dash='dash', color='blue')))
        fig_ms.add_trace(go.Scatter(x=sorted_models, y=test_r2, mode='lines+markers', name='Test RÂ²', line=dict(color='red', width=3)))
        fig_ms.update_layout(yaxis_range=[0.2, 0.9])
        st.plotly_chart(fig_ms, use_container_width=True)
        
        st.info("ğŸ“¢ **íšŒê·€ ëª¨ë¸ ì¤‘ ìµœì ì˜ ëª¨ë¸(XGBoost) í™•ì¸**")

    with sub_tab3:
        st.markdown("#### Final Regression Model Limit")
        comp_df = pd.DataFrame({
            "Metric": ["Train RÂ²", "Test RÂ²", "Gap"],
            "Base Model (Plus)": ["0.580", "0.585", "-0.005"], 
            "Final Model (XGB)": ["0.795", "0.664", "0.131"]
        })
        st.table(comp_df.set_index("Metric"))
        
        st.markdown(f"""
        <div class="warning-box" style="text-align: center; font-size: 18px;">
        <b>"ìµœì¢… íšŒê·€ ëª¨ë¸ Test RÂ² 0.664 ë‹¬ì„± í–ˆìœ¼ë‚˜, Train-Test ê°„ ê²©ì°¨ë¡œ ì¸í•œ ê³¼ì í•© ìš°ë ¤ì™€<br>
        íšŒê·€ ëª¨ë¸ì˜ ì„±ëŠ¥ í•œê³„ ë„ë‹¬ë¡œ ë¶„ë¥˜ ëª¨ë¸ë¡œì˜ ì „í™˜ í•„ìš”ì„± í™•ì¸"</b>
        </div>
        """, unsafe_allow_html=True)

# ==============================================================================
# TAB 4: CLASSIFICATION ANALYSIS
# ==============================================================================
with tab_cls:
    st.subheader("Classification Model Comparison")
    st.markdown("""
    <div class="info-box">
    <b>ëª¨ë¸ ì „í™˜ ì „ëµ:</b><br>
    íšŒê·€ë¶„ì„ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ <b>ë‹¤ì¤‘ ë¶„ë¥˜(Multi-Class Classification)</b>ë¡œ ë¬¸ì œë¥¼ ì¬ì •ì˜í•˜ì˜€ìŠµë‹ˆë‹¤.<br>
    5ê°œ ì•Œê³ ë¦¬ì¦˜ì— ëŒ€í•´ <b>3ë…„ ë¡¤ë§ ìœˆë„ìš°ë¥¼</b>ì„ ì ìš©í•˜ì—¬ ROC-AUCë¥¼ ë¹„êµ ë¶„ì„í•˜ì˜€ìŠµë‹ˆë‹¤.
    </div>
    """, unsafe_allow_html=True)
    
    sub_roc, sub_param = st.tabs(["ROC AUC", "Parameter Tuning"])
    
    # [4-1] ROC AUC (Smoothed Curves & New Models)
    with sub_roc:
        st.markdown("#### Multi-Model ROC Comparison (Macro-average)")
        
        # Hardcoded smoothed data points for 5 models
        # XGBoost (0.823) - Best
        fpr_xgb = [0, 0.05, 0.1, 0.2, 0.3, 0.4, 0.6, 0.8, 1]
        tpr_xgb = [0, 0.35, 0.55, 0.72, 0.83, 0.89, 0.95, 0.98, 1]
        
        # LGBM (0.819)
        fpr_lgbm = [0, 0.05, 0.1, 0.2, 0.3, 0.4, 0.6, 0.8, 1]
        tpr_lgbm = [0, 0.33, 0.53, 0.70, 0.81, 0.88, 0.94, 0.97, 1]
        
        # Random Forest (0.809)
        fpr_rf = [0, 0.05, 0.1, 0.2, 0.3, 0.4, 0.6, 0.8, 1]
        tpr_rf = [0, 0.30, 0.50, 0.68, 0.79, 0.86, 0.93, 0.96, 1]
        
        # SVM (0.805)
        fpr_svm = [0, 0.05, 0.1, 0.2, 0.3, 0.4, 0.6, 0.8, 1]
        tpr_svm = [0, 0.28, 0.48, 0.66, 0.78, 0.85, 0.92, 0.96, 1]
        
        # Logistic (0.800)
        fpr_log = [0, 0.05, 0.1, 0.2, 0.3, 0.4, 0.6, 0.8, 1]
        tpr_log = [0, 0.27, 0.47, 0.65, 0.77, 0.84, 0.91, 0.95, 1]

        fig_roc = go.Figure()
        fig_roc.add_trace(go.Scatter(x=[0,1], y=[0,1], line=dict(dash='dash', color='gray'), name='Random'))
        
        # Add traces with spline smoothing
        fig_roc.add_trace(go.Scatter(x=fpr_xgb, y=tpr_xgb, name='XGBoost (AUC = 0.823)', line=dict(color=COLOR_MAIN, width=4, shape='spline')))
        fig_roc.add_trace(go.Scatter(x=fpr_lgbm, y=tpr_lgbm, name='LGBM (AUC = 0.819)', line=dict(color=COLOR_ACCENT, width=2, shape='spline')))
        fig_roc.add_trace(go.Scatter(x=fpr_rf, y=tpr_rf, name='Random Forest (AUC = 0.809)', line=dict(color='green', width=2, shape='spline')))
        fig_roc.add_trace(go.Scatter(x=fpr_svm, y=tpr_svm, name='SVM (AUC = 0.805)', line=dict(color='orange', width=2, shape='spline')))
        fig_roc.add_trace(go.Scatter(x=fpr_log, y=tpr_log, name='Logistic (AUC = 0.800)', line=dict(color='blue', width=2, shape='spline')))
        
        fig_roc.update_layout(title="Multi-Model ROC Comparison", xaxis_title="FPR", yaxis_title="TPR", height=600)
        st.plotly_chart(fig_roc, use_container_width=True)
        
        st.success("âœ… **XGBoost**ê°€ AUC ë° ì•ˆì •ì„± ì¸¡ë©´ì—ì„œ ê°€ì¥ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì—¬ ìµœì¢… ëª¨ë¸ë¡œ ì„ ì •")

    # [4-2] Parameter Tuning (Provided Data)
    with sub_param:
        st.markdown("#### Max Depth Tuning (Overfitting Check)")
        
        col_p1, col_p2 = st.columns(2)
        
        # Data
        depths = list(range(3, 21))
        # Left Chart: Test 2024
        test_auc_24 = [0.8028, 0.8161, 0.8231, 0.8265, 0.8290, 0.8308, 0.8311, 0.8305, 0.8312, 0.8317, 0.8300, 0.8297, 0.8299, 0.8303, 0.8309, 0.8309, 0.8320, 0.8312]
        
        # Right Chart: Test 2023 (Validation)
        test_auc_23 = [0.7781, 0.7816, 0.7835, 0.7863, 0.7873, 0.7829, 0.7831, 0.7797, 0.7811, 0.7798, 0.7810, 0.7795, 0.7806, 0.7800, 0.7782, 0.7812, 0.7794, 0.7787]
        
        with col_p1:
            fig_p1 = go.Figure()
            fig_p1.add_trace(go.Scatter(x=depths, y=test_auc_24, name="Test (Window Size)", line=dict(color='red')))
            fig_p1.add_trace(go.Scatter(x=[7], y=[0.8290], mode='markers', marker=dict(size=15, color='blue'), name='Slowing Point (Depth 7)'))
            fig_p1.add_trace(go.Scatter(x=[19], y=[0.8320], mode='markers', marker=dict(size=15, color='orange'), name='Best (Depth 19)'))
            fig_p1.update_layout(title="Finding Optimal Max_Depth (Current Year)", xaxis_title="Max Depth", yaxis_title="AUC")
            st.plotly_chart(fig_p1, use_container_width=True)
            
            st.info("ğŸ“¢ **Best ScoreëŠ” 19ì´ì§€ë§Œ, Depth 7ë¶€í„° ê¸‰ê²©í•œ ì„±ì¥ ì™„í™” í™•ì¸**")
            
        with col_p2:
            fig_p2 = go.Figure()
            fig_p2.add_trace(go.Scatter(x=depths, y=test_auc_23, name="Test (2023 Validation)", line=dict(color='green', width=3)))
            # Highlight 7
            fig_p2.add_trace(go.Scatter(x=[7], y=[0.7873], mode='markers', marker=dict(size=15, color='orange'), name='Best (Depth 7)'))
            fig_p2.update_layout(title="Cross-Validation Like Check (Past Year)", xaxis_title="Max Depth", yaxis_title="AUC")
            st.plotly_chart(fig_p2, use_container_width=True)

            st.info("ğŸ“¢ **Best Score 7ë¡œ ì„±ì¥ê³¡ì„  êµì°¨ê²€ì¦ ì™„ë£Œ**")
            
        st.markdown(f"""
        <div style="text-align: center; background-color: {COLOR_MAIN}; color: white; padding: 10px; border-radius: 5px;">
        <b>ìµœì  íŒŒë¼ë¯¸í„° (max_depth = 7) ë„ì¶œ: ê³¼ì í•© ë°©ì§€ ë° ì¼ë°˜í™” ì„±ëŠ¥ í™•ë³´</b>
        </div>
        """, unsafe_allow_html=True)

# ==============================================================================
# TAB 5: FINAL MODEL
# ==============================================================================
with tab_final:
    st.subheader("Final Model Analysis (XGBoost Depth 7)")
    st.markdown("""
    <div class="info-box">
    <b>ìµœì¢… ëª¨ë¸ ì„ ì • ì´ìœ :</b><br>
    Depth 19 ëª¨ë¸ì´ ì ìˆ˜ëŠ” ë” ë†’ì•˜ìœ¼ë‚˜(0.832), ê³¼ê±° ë°ì´í„° ê²€ì¦ ì‹œ ê³¼ì í•©ì´ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.<br>
    ë”°ë¼ì„œ <b>ì¼ë°˜í™” ì„±ëŠ¥ì´ ê²€ì¦ëœ Depth 7 (AUC 0.829)</b>ì„ ìµœì¢… ëª¨ë¸ë¡œ ì±„íƒí•˜ì˜€ìŠµë‹ˆë‹¤.
    </div>
    """, unsafe_allow_html=True)
    
    if 'final' in models:
        final_model = models['final']
        last_model = final_model.estimators[-1]['model']
        last_scaler = final_model.estimators[-1]['scaler']
        
        sub_score, sub_shap = st.tabs(["Final Score & Importance", "SHAP Analysis"])
        
        with sub_score:
            c1, c2 = st.columns(2)
            with c1:
                st.markdown("#### Feature Importance (All_Features)")
                if hasattr(last_scaler, 'feature_names_in_'):
                    feat_names = last_scaler.feature_names_in_
                else:
                    feat_names = X_adv.columns
                
                importances = last_model.feature_importances_
                fi_df = pd.DataFrame({'Feature': feat_names, 'Importance': importances})
                fi_df = fi_df[~fi_df['Feature'].str.startswith('IND_')].sort_values(by='Importance', ascending=True).tail(20)
                
                fig_imp = px.bar(fi_df, x='Importance', y='Feature', orientation='h')
                fig_imp.update_traces(marker_color=COLOR_MAIN)
                fig_imp.update_layout(height=500)
                st.plotly_chart(fig_imp, use_container_width=True)
                
            with c2:
                st.markdown("#### Final Model ROC - AUC Curve")
                # Hard-coded from Image Data (Slightly better than XGBoost in Multi-model)
                fpr_final = [0, 0.05, 0.15, 0.3, 0.5, 0.8, 1]
                tpr_final = [0, 0.32, 0.58, 0.78, 0.90, 0.96, 1] # Slightly smoothed
                
                fig_roc = go.Figure()
                fig_roc.add_trace(go.Scatter(x=fpr_final, y=tpr_final, fill='tozeroy', 
                                             name='Macro AUC (0.829)', 
                                             line=dict(color=COLOR_MAIN, width=3, shape='spline')))
                fig_roc.add_trace(go.Scatter(x=[0,1], y=[0,1], line=dict(dash='dash', color='gray')))
                fig_roc.update_layout(height=500, xaxis_title="FPR", yaxis_title="TPR")
                st.plotly_chart(fig_roc, use_container_width=True)

        with sub_shap:
            st.markdown("#### SHAP Beeswarm Analysis")
            st.info(
                    "SHAP_Analysis: AIê°€ ì™œ ì´ëŸ° ê²°ê³¼ë¥¼ ëƒˆëŠ”ì§€, "
                    "ì–´ë–¤ í•­ëª©ì´ ê²°ê³¼ì— ê°€ì¥ í° ì˜í–¥ì„ ì¤¬ëŠ”ì§€ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.\n\n"
                    "ğŸ“Š ê·¸ë˜í”„ ì½ëŠ” ë²•\n"
                    "â€¢ ìœ„ì— ìˆì„ìˆ˜ë¡ ê²°ê³¼ì— ë” ì¤‘ìš”í•œ í•­ëª©ì…ë‹ˆë‹¤\n"
                    "â€¢ ì˜¤ë¥¸ìª½ì¼ìˆ˜ë¡ ê²°ê³¼ë¥¼ ë†’ì´ëŠ” ì˜í–¥, ì™¼ìª½ì¼ìˆ˜ë¡ ë‚®ì¶”ëŠ” ì˜í–¥ì…ë‹ˆë‹¤\n"
                    "â€¢ ì ì´ ë§ì„ìˆ˜ë¡ í•´ë‹¹ ì‚¬ë¡€ê°€ ìì£¼ ë‚˜íƒ€ë‚œë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤"
                    )

            
            try:
                X_sample = X_adv.sample(min(100, len(X_adv)))
                if hasattr(last_scaler, 'feature_names_in_'):
                    X_sample = X_sample.reindex(columns=last_scaler.feature_names_in_, fill_value=0)
                
                X_scaled = last_scaler.transform(X_sample)
                explainer = shap.TreeExplainer(last_model)
                shap_values = explainer.shap_values(X_scaled)
                
                non_ind_cols = [c for c in X_sample.columns if not c.startswith('IND_')]
                keep_idx = [X_sample.columns.get_loc(c) for c in non_ind_cols]
                
                X_vis = X_sample[non_ind_cols]
                
                col_s1, col_s2 = st.columns(2)
                
                with col_s1:
                    st.markdown("##### Grade 1 (Lowest) Drivers")
                    if isinstance(shap_values, list):
                        shap_v = shap_values[0][:, keep_idx]
                    else:
                        shap_v = shap_values[:, keep_idx, 0]
                        
                    plt.figure()
                    shap.summary_plot(shap_v, X_vis, show=False, plot_size=(5, 5))
                    st.pyplot(plt.gcf())
                    
                with col_s2:
                    st.markdown("##### Grade 6 (Highest) Drivers")
                    if isinstance(shap_values, list):
                        shap_v = shap_values[-1][:, keep_idx]
                    else:
                        shap_v = shap_values[:, keep_idx, -1]
                        
                    plt.figure()
                    shap.summary_plot(shap_v, X_vis, show=False, plot_size=(5, 5))
                    st.pyplot(plt.gcf())
                    
            except Exception as e:
                st.error(f"SHAP Visualization Error: {e}")

# ==============================================================================
# TAB 6: PREDICTOR
# ==============================================================================
with tab_pred:
    st.subheader("AI ESG Predictor & Advisor")
    
    if 'final' in models:
        final_model = models['final']
        sub_search, sub_sim = st.tabs(["ğŸ” Company Search", "ğŸ›ï¸ Feature Simulation"])
        
        with sub_search:
            c1, c2, c3 = st.columns([2, 1, 1])
            with c1:
                search_term = st.text_input("ê¸°ì—…ëª…/ì½”ë“œ ê²€ìƒ‰", placeholder="ì˜ˆ: ì‚¼ì„±ì „ì")
            with c2:
                years = sorted(full_search_df['year'].unique(), reverse=True)
                t_year = st.selectbox("ì˜ˆì¸¡ ì—°ë„", years)
            with c3:
                st.write("")
                st.write("")
                btn_search = st.button("ê²€ìƒ‰ ì‹¤í–‰")
                
            if btn_search and search_term:
                found = full_search_df[
                    (full_search_df['corp_name'].str.contains(search_term)) & 
                    (full_search_df['year'] == t_year)
                ]
                
                if found.empty:
                    st.error("ë°ì´í„° ì—†ìŒ")
                else:
                    target = found.iloc[0]
                    input_df = pd.DataFrame([target])
                    model_in = pd.DataFrame(0, index=[0], columns=X_adv.columns)
                    
                    for c in X_adv.columns:
                        if c in input_df: model_in[c] = input_df[c].values
                        elif c.startswith('IND_') and 'IND' in input_df:
                            if f"IND_{input_df['IND'].values[0]}" == c: model_in[c] = 1
                            
                    prob = final_model.predict_proba(model_in)[0]
                    pred = le.inverse_transform([np.argmax(prob)])[0]
                    
                    st.divider()
                    m1, m2, m3 = st.columns(3)
                    with m1:
                        st.metric("AI ì˜ˆì¸¡ ë“±ê¸‰", f"{pred}")
                    with m2:
                        real = target['ESG'] if 'ESG' in target else "-"
                        st.metric("ì‹¤ì œ ë“±ê¸‰", f"{real}")
                    with m3:
                        st.metric("Model Reliability (AUC)", "0.829")
                    
                    st.progress(float(max(prob)))
                    st.caption(f"Instance Confidence: {max(prob)*100:.1f}%")

        with sub_sim:
            st.info("ğŸ“Š ê° ì§€í‘œì˜ í‰ê· ê°’(Mean)ìœ¼ë¡œ ì´ˆê¸°í™”ëœ ìƒíƒœì—ì„œ ì‹œë®¬ë ˆì´ì…˜ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
# ----------------------------------------------------------------------------------------            
            # 1. ëª¨ë¸ ì„ íƒ UI ì¶”ê°€
            model_choice = st.radio("ğŸ¯ ë¶„ì„ ëª¨ë¸ ì„ íƒ", ["ê¸°ë³¸ ëª¨ë¸ (19ê°œ)", "í™•ì¥í˜• ëª¨ë¸ (21ê°œ - ì „ë…„ë„ ESGë“±ê¸‰ í•„ìš”)"], horizontal=True)
            is_extended = "í™•ì¥í˜•" in model_choice
# ----------------------------------------------------------------------------------------


            defaults = X_adv.mean()
            # 15 Features Requested
            req_feats = ['SGAE_R', 'Fe_R', 'Re_R', 'SA', 'Pay_Gap', 'W_YEAR', 'TQ', 'SGR', 'MSE', 'FOR', 'DIV', 'DIR_FE', 'LEV', 'ROA', 'DIR_OUT']
            # Binary Cols
            binary_cols = ['DIV_enco', 'DIR_FE_enco'] 
            
            with st.form("sim_form"):
                inputs = {}
                cols = st.columns(4)
                
                # [ê¸°ë³¸ 19ê°œ ë³€ìˆ˜ ì…ë ¥ ê·¸ë¦¬ë“œ]
                idx = 0
                for c in X_adv.columns:
                    # Skip IND_
                    if c.startswith('IND_'): continue
                    
                    with cols[idx % 4]:
                        if c in binary_cols:
                            inputs[c] = st.selectbox(c, [0, 1], index=0)
                        elif c in req_feats: 
                            val = float(defaults[c])
                            inputs[c] = st.number_input(c, value=val)
                        else:
                            val = float(defaults[c])
                            inputs[c] = st.number_input(c, value=val)
                    idx += 1
                inds = [c.replace('IND_', '') for c in X_adv.columns if c.startswith('IND_')]
                sel_ind = st.selectbox("ì‚°ì—…êµ°", inds)


# ----------------------------------------------------------------------------------------
                # 2. í™•ì¥í˜• ë³€ìˆ˜ ì…ë ¥ í•„ë“œ ì¶”ê°€
                esg_lag_val = 0
                if is_extended:
                    st.divider()
                    st.subheader("í™•ì¥ ë³€ìˆ˜ ì„¤ì •")
                    lag_col1, lag_col2 = st.columns(2)
                    with lag_col1:
                        # ì „ë…„ë„ ë“±ê¸‰ì„ ìˆ«ìë¡œ ë§¤í•‘ (ê¸°ì¡´ ë§¤í•‘ í™œìš©)
                        lag_label = st.selectbox("ì „ë…„ë„ ESG ë“±ê¸‰ (ESG_lag)", ["S", "A+", "A", "B+", "B", "C", "D"], index=2)
                        esg_mapping_rev = {"S": 7, "A+": 6, "A": 5, "B+": 4, "B": 3, "C": 2, "D": 1}
                        esg_lag_val = esg_mapping_rev[lag_label]
                    with lag_col2:
                        # ìƒí˜¸ì‘ìš© ë³€ìˆ˜ëŠ” ìë™ ê³„ì‚°ë¨ì„ ì•ˆë‚´
                        st.info(f"**ìƒí˜¸ì‘ìš© ë³€ìˆ˜ ìë™ ê³„ì‚°**: A_SIZE Ã— FOR")

# ----------------------------------------------------------------------------------------                
                
                btn_run = st.form_submit_button("ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰")
            
            if btn_run:
# ----------------------------------------------------------------------------------------               
                # 3. ëª¨ë¸ ì„ íƒ ë¡œì§
                if is_extended:
                    current_model = models.get('ext_model')
                    # í™•ì¥í˜•ì€ ë¡¤ë§ ìœˆë„ìš°ê°€ ì•„ë‹Œ ë‹¨ì¼ ëª¨ë¸ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ êµ¬ì¡° ëŒ€ì‘
                    explainer_model = current_model
                    scaler_obj = models.get('ext_scaler')
                else:
                    current_model = models['final']
                    explainer_model = current_model.estimators[-1]['model']
                    scaler_obj = current_model.estimators[-1]['scaler']
# ----------------------------------------------------------------------------------------

                sim_df = pd.DataFrame([inputs])
                model_in = pd.DataFrame(0, index=[0], columns=X_adv.columns)
                for c in X_adv.columns:
                    if c in sim_df: model_in[c] = sim_df[c]
                    if c == f"IND_{sel_ind}": model_in[c] = 1
# ----------------------------------------------------------------------------------------                
                # âœ… í™•ì¥ ë³€ìˆ˜ ì¶”ê°€ ë¡œì§
                if is_extended:
                    model_in["ESG_lag"] = esg_lag_val
                    model_in["A_SIZE_FOR_inter"] = float(inputs["A_SIZE"]) * float(inputs["FOR"])


                # ìŠ¤ì¼€ì¼ëŸ¬ê°€ ì•Œê³  ìˆëŠ” ìˆœì„œëŒ€ë¡œ ì •ë ¬ í›„ ë³€í™˜
                model_in_aligned = model_in.reindex(columns=scaler_obj.feature_names_in_, fill_value=0)
                X_scaled = scaler_obj.transform(model_in_aligned)

# ----------------------------------------------------------------------------------------

                prob = final_model.predict_proba(model_in)[0]
                curr_idx = np.argmax(prob)
                curr_grade = le.inverse_transform([curr_idx])[0]
                
                c_res, c_radar = st.columns([1, 2])
                with c_res:
                    st.metric("Simulated Grade", curr_grade)
                    st.metric("Model Reliability", "0.829")
                with c_radar:
                    fig_radar = go.Figure(go.Scatterpolar(
                        r=prob, theta=le.classes_, fill='toself', line_color=COLOR_MAIN
                    ))
                    fig_radar.update_layout(polar=dict(radialaxis=dict(visible=True)), height=400)
                    st.plotly_chart(fig_radar, use_container_width=True)
                
                # st.markdown("### ğŸ¤– AI Improvement Strategy")
                
                # hierarchy = ['D', 'C', 'B', 'B+', 'A', 'A+', 'S']
                # valid_hierarchy = [g for g in hierarchy if g in le.classes_]
                
                # if curr_grade in valid_hierarchy:
                #     current_rank = valid_hierarchy.index(curr_grade)
                #     if current_rank < len(valid_hierarchy) - 1:
                #         target_grade = valid_hierarchy[current_rank + 1]
                #         target_idx = le.transform([target_grade])[0]
                        
                #         st.write(f"**Goal: {curr_grade} $\\rightarrow$ {target_grade}** ë‹¬ì„±ì„ ìœ„í•œ ì£¼ìš” ë³€ìˆ˜ ì œì•ˆ")
                        
                #         advice = []
                #         base_prob = prob[target_idx]
                        
                #         for f in req_feats:
                #             if f not in inputs: continue
                #             temp_in = model_in.copy()
                #             val = temp_in.loc[0, f]
                #             if f in binary_cols: continue
                            
                #             delta = val * 0.1 if val != 0 else 0.01
                            
                #             temp_in.loc[0, f] = val + delta
                #             p_up = final_model.predict_proba(temp_in)[0][target_idx]
                            
                #             temp_in.loc[0, f] = val - delta
                #             p_down = final_model.predict_proba(temp_in)[0][target_idx]
                            
                #             if f == 'LEV':
                #                 if p_down > base_prob: advice.append((f, "ê°ì†Œ(-)", (p_down - base_prob)*100))
                #             elif f in ['Pay_Gap', 'Fe_R']:
                #                 if val < 0 and p_up > base_prob: advice.append((f, "ì¦ê°€(+)", (p_up - base_prob)*100))
                #                 elif val > 0 and p_down > base_prob: advice.append((f, "ê°ì†Œ(-)", (p_down - base_prob)*100))
                #             else:
                #                 if p_up > base_prob: advice.append((f, "ì¦ê°€(+)", (p_up - base_prob)*100))
                                
                #         advice.sort(key=lambda x: x[2], reverse=True)
                #         if advice:
                #             for f, direct, gain in advice[:3]:
                #                 st.markdown(f"- **{f}** {direct}: í™•ë¥  **+{gain:.2f}%p** ìƒìŠ¹ ì˜ˆìƒ")
                #         else:
                #             st.info("í˜„ì¬ ë³€ìˆ˜ ì¡°ì •ìœ¼ë¡œëŠ” ìœ ì˜ë¯¸í•œ ë“±ê¸‰ ìƒìŠ¹ í™•ë¥ ì„ ì°¾ê¸° ì–´ë µìŠµë‹ˆë‹¤.")
                #     else:
                #         st.success("ì´ë¯¸ ìµœê³  ë“±ê¸‰ì…ë‹ˆë‹¤!")



            
            if btn_run:

# ----------------------------------------------------------------------------------------
                # --- [A] ì‚¬ìš©ìê°€ ì„ íƒí•œ ëª¨ë“œì— ë”°ë¼ ëª¨ë¸ê³¼ ì €ìš¸(Scaler) ë°”êµ¬ë‹ˆ ì±„ìš°ê¸° ---
                if is_extended:
                    # í™•ì¥í˜• ì„ íƒ ì‹œ: í™•ì¥í˜• ì „ìš© ëª¨ë¸ê³¼ ì €ìš¸ ì‚¬ìš©
                    current_model = models.get('ext_model')
                    scaler_obj = models.get('ext_scaler') 
                    explainer_model = current_model # SHAP ë¶„ì„ìš© ëª¨ë¸
                else:
                    # ê¸°ë³¸í˜• ì„ íƒ ì‹œ: ê¸°ë³¸í˜•ì˜ ë¡¤ë§ ìœˆë„ìš° ëª¨ë¸ ì¤‘ ë§ˆì§€ë§‰ ì €ìš¸ê³¼ ëª¨ë¸ êº¼ë‚´ê¸°
                    current_ensemble = models['final']
                    scaler_obj = current_ensemble.estimators[-1]['scaler']
                    explainer_model = current_ensemble.estimators[-1]['model']
# ----------------------------------------------------------------------------------------                
                
                
                # 1. ì˜ˆì¸¡ ì‹¤í–‰
                sim_df = pd.DataFrame([inputs])
                model_in = pd.DataFrame(0, index=[0], columns=X_adv.columns)
                for c in X_adv.columns:
                    if c in sim_df: model_in[c] = sim_df[c]
                    if c == f"IND_{sel_ind}": model_in[c] = 1

# ----------------------------------------------------------------------------------------               
                # âœ… í™•ì¥í˜• ëª¨ë¸ì¼ ë•Œë§Œ ì‹ ê·œ ë³€ìˆ˜ 2ê°œ ì¶”ê°€

                if is_extended:
                    model_in["ESG_lag"] = esg_lag_val
                    model_in["A_SIZE_FOR_inter"] = float(inputs["A_SIZE"]) * float(inputs["FOR"])


                # ìŠ¤ì¼€ì¼ëŸ¬ê°€ ì•Œê³  ìˆëŠ” ìˆœì„œëŒ€ë¡œ ì •ë ¬ í›„ ë³€í™˜
                model_in_aligned = model_in.reindex(columns=scaler_obj.feature_names_in_, fill_value=0)
                X_scaled = scaler_obj.transform(model_in_aligned)

# ----------------------------------------------------------------------------------------

                prob = final_model.predict_proba(model_in)[0]
                curr_idx = np.argmax(prob)
                curr_grade = le.inverse_transform([curr_idx])[0]

# -----------------------------------------------------------------------------------------
# ---------------------------------------------------------
                # 4. SHAP ë¶„ì„ (ëª¨ë¸ì— ë”°ë¼ 19ê°œ vs 21ê°œ ìë™ ì „í™˜)
                # ---------------------------------------------------------
                st.divider()
                st.subheader("ğŸ” SHAP ê¸°ë°˜ ìƒì„¸ ë¶„ì„")
                
                try:
                    explainer = shap.TreeExplainer(explainer_model)
                    shap_values = explainer.shap_values(X_scaled)
                    
                    if isinstance(shap_values, list):
                        vals_for_class = shap_values[curr_idx][0, :]
                    else:
                        vals_for_class = shap_values[0, :, curr_idx]

                    # ğŸ’¡ í•µì‹¬: ì‚°ì—…êµ°(IND_)ë§Œ ì œì™¸í•˜ë©´, ë‚˜ë¨¸ì§€ëŠ” ëª¨ë¸ì´ ê°€ì§„ í”¼ì²˜(19ê°œ ë˜ëŠ” 21ê°œ)ê°€ ìë™ìœ¼ë¡œ ë‚¨ìŒ!
                    feature_names = list(scaler_obj.feature_names_in_)
                    non_ind_indices = [i for i, name in enumerate(feature_names) if not name.startswith("IND_")] 
                    
                    new_values = np.array([vals_for_class[i] for i in non_ind_indices], dtype=np.float64)
                    new_feature_names = [feature_names[i] for i in non_ind_indices]
                    new_data = np.array([round(float(model_in_aligned.iloc[0][feature_names[i]]), 2) for i in non_ind_indices], dtype=np.float64)

                    base_val = explainer.expected_value
                    if isinstance(base_val, (list, np.ndarray)):
                        base_val = base_val[curr_idx]
                    
                    exp = shap.Explanation(
                        values=new_values,
                        base_values=float(base_val),
                        data=new_data,
                        feature_names=new_feature_names
                    )

                    with st.expander(f"ğŸ“ {model_choice} ìƒì„¸ ë¶„ì„ SHAP", expanded=True):
                        # [í•µì‹¬ ìˆ˜ì •] ë§ˆì´ë„ˆìŠ¤ ë¶€í˜¸ ì„¤ì •ì„ ê°€ì¥ ê°•ë ¥í•˜ê²Œ ì ìš©
                        import matplotlib.pyplot as plt
                        import koreanize_matplotlib

                        # 1. ë§ˆì´ë„ˆìŠ¤ ë¶€í˜¸ ê¹¨ì§ ë°©ì§€ (ë°˜ë“œì‹œ Falseì—¬ì•¼ í•¨)
                        plt.rcParams['axes.unicode_minus'] = False
                        
                        # 2. í°íŠ¸ ì¬ì„¤ì • (í˜¹ì‹œ ëª¨ë¥¼ ì„¤ì • ë®ì–´ì“°ê¸° ë°©ì§€)
                        # NanumGothicì´ ì—†ìœ¼ë©´ ê¸°ë³¸ í•œê¸€ í°íŠ¸ë¡œ ëŒ€ì²´í•˜ë„ë¡ ì„¤ì •
                        plt.rcParams['font.family'] = ['NanumGothic', 'Malgun Gothic', 'AppleGothic', 'sans-serif']

                        total_features = len(new_values)
                        
                        # 3. Figure ê°ì²´ ëª…ì‹œì  ìƒì„±
                        fig, ax = plt.subplots(figsize=(10, 0.6 * total_features + 2))
                        
                        # 4. SHAP ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
                        shap.plots.waterfall(exp, show=False, max_display=total_features)
                        
                        # 5. íƒ€ì´í‹€ ì„¤ì •
                        plt.title(f"{curr_grade} ë“±ê¸‰ íŒì • í•µì‹¬ ìš”ì¸ (ë³€ìˆ˜ {total_features}ê°œ)", fontsize=15, pad=30)
                        
                        # 6. Streamlitì— ì¶œë ¥
                        st.pyplot(fig)
                        plt.close(fig)



                    # ---------------------------------------------------------
                    # 5. ì „ëµ ì œì•ˆ ìë™ ìƒì„±
                    # ---------------------------------------------------------
                    st.subheader("ğŸ’¡ AI ë§ì¶¤í˜• ì „ëµ ì²˜ë°©")
                    tmp_analysis_df = pd.DataFrame({"feature": new_feature_names, "shap": new_values})
                    tmp_analysis_df["abs_shap"] = tmp_analysis_df["shap"].abs()
                    tmp_analysis_df = tmp_analysis_df.sort_values("abs_shap", ascending=False)
                    
                    advice_pack = make_shap_based_advice(tmp_analysis_df, model_in, STRATEGIC_ADVICE, top_k=3)
                    
                    col_pos, col_neg = st.columns(2)
                    with col_pos:
                        st.markdown("##### âœ… ìœ ì§€ ë° ê°•í™” ì „ëµ")
                        for item in advice_pack["pos"]:
                            st.success(f"**{item['feature']}**: {item['text']}")
                    with col_neg:
                        st.markdown("##### âš ï¸ ê°œì„  ë° ë³´ì™„ ì „ëµ")
                        for item in advice_pack["neg"]:
                            st.warning(f"**{item['feature']}**: {item['text']}")

                except Exception as e:
                    st.error(f"SHAP ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")